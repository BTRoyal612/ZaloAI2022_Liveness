{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USAGE\n",
    "# python train_liveness.py --dataset dataset --model liveness.model --le le.pickle\n",
    "\n",
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "# import the necessary packages\n",
    "from livenessnet import LivenessNet\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "\n",
    "real_path = r'D:\\ZaloAI\\LIVENESS\\dataset\\real_img'\n",
    "for filename in os.scandir(real_path):\n",
    "    real_img = cv2.imread(filename.path)\n",
    "    data.append(real_img)\n",
    "    labels.append(\"real\")\n",
    "\n",
    "fake_path = r'D:\\ZaloAI\\LIVENESS\\dataset\\fake_img'\n",
    "for filename in os.scandir(fake_path):\n",
    "    fake_img = cv2.imread(filename.path)\n",
    "    data.append(fake_img)\n",
    "    labels.append(\"fake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gbhoa\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network for 50 epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gbhoa\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1935: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "508/508 [==============================] - 13s 13ms/step - loss: 0.9311 - accuracy: 0.5505 - val_loss: 0.7286 - val_accuracy: 0.5873\n",
      "Epoch 2/50\n",
      "508/508 [==============================] - 6s 11ms/step - loss: 0.8537 - accuracy: 0.5731 - val_loss: 0.6803 - val_accuracy: 0.6308\n",
      "Epoch 3/50\n",
      "508/508 [==============================] - 5s 10ms/step - loss: 0.7860 - accuracy: 0.5911 - val_loss: 0.6703 - val_accuracy: 0.6404\n",
      "Epoch 4/50\n",
      "508/508 [==============================] - 5s 10ms/step - loss: 0.7513 - accuracy: 0.6103 - val_loss: 0.6701 - val_accuracy: 0.6308\n",
      "Epoch 5/50\n",
      "508/508 [==============================] - 5s 10ms/step - loss: 0.7479 - accuracy: 0.6081 - val_loss: 0.6441 - val_accuracy: 0.6603\n",
      "Epoch 6/50\n",
      "508/508 [==============================] - 5s 10ms/step - loss: 0.7025 - accuracy: 0.6359 - val_loss: 0.5979 - val_accuracy: 0.6971\n",
      "Epoch 7/50\n",
      "508/508 [==============================] - 5s 10ms/step - loss: 0.6889 - accuracy: 0.6457 - val_loss: 0.6223 - val_accuracy: 0.6986\n",
      "Epoch 8/50\n",
      "508/508 [==============================] - 5s 10ms/step - loss: 0.6809 - accuracy: 0.6477 - val_loss: 0.5973 - val_accuracy: 0.7074\n",
      "Epoch 9/50\n",
      "508/508 [==============================] - 5s 10ms/step - loss: 0.6683 - accuracy: 0.6541 - val_loss: 0.5854 - val_accuracy: 0.7038\n",
      "Epoch 10/50\n",
      "508/508 [==============================] - 5s 10ms/step - loss: 0.6508 - accuracy: 0.6679 - val_loss: 0.5760 - val_accuracy: 0.7244\n",
      "Epoch 11/50\n",
      "508/508 [==============================] - 5s 10ms/step - loss: 0.6344 - accuracy: 0.6864 - val_loss: 0.5993 - val_accuracy: 0.7089\n",
      "Epoch 12/50\n",
      "508/508 [==============================] - 5s 10ms/step - loss: 0.6320 - accuracy: 0.6819 - val_loss: 0.5574 - val_accuracy: 0.7310\n",
      "Epoch 13/50\n",
      "508/508 [==============================] - 5s 10ms/step - loss: 0.6204 - accuracy: 0.6856 - val_loss: 0.5822 - val_accuracy: 0.7030\n",
      "Epoch 14/50\n",
      "508/508 [==============================] - 5s 10ms/step - loss: 0.6162 - accuracy: 0.6859 - val_loss: 0.6028 - val_accuracy: 0.7126\n",
      "Epoch 15/50\n",
      "508/508 [==============================] - 5s 10ms/step - loss: 0.6170 - accuracy: 0.6713 - val_loss: 0.5479 - val_accuracy: 0.7266\n",
      "Epoch 16/50\n",
      "508/508 [==============================] - 5s 10ms/step - loss: 0.6024 - accuracy: 0.6918 - val_loss: 0.6211 - val_accuracy: 0.6831\n",
      "Epoch 17/50\n",
      "508/508 [==============================] - 5s 10ms/step - loss: 0.6020 - accuracy: 0.6876 - val_loss: 0.5707 - val_accuracy: 0.6971\n",
      "Epoch 18/50\n",
      "508/508 [==============================] - 5s 10ms/step - loss: 0.5955 - accuracy: 0.6947 - val_loss: 0.5562 - val_accuracy: 0.7148\n",
      "Epoch 19/50\n",
      "508/508 [==============================] - 5s 10ms/step - loss: 0.5880 - accuracy: 0.6965 - val_loss: 0.5226 - val_accuracy: 0.7561\n",
      "Epoch 20/50\n",
      "508/508 [==============================] - 5s 10ms/step - loss: 0.5928 - accuracy: 0.6937 - val_loss: 0.5198 - val_accuracy: 0.7487\n",
      "Epoch 21/50\n",
      "508/508 [==============================] - 5s 10ms/step - loss: 0.5761 - accuracy: 0.7137 - val_loss: 0.5232 - val_accuracy: 0.7502\n",
      "Epoch 22/50\n",
      "508/508 [==============================] - 5s 10ms/step - loss: 0.5799 - accuracy: 0.7056 - val_loss: 0.5318 - val_accuracy: 0.7428\n",
      "Epoch 23/50\n",
      "508/508 [==============================] - 5s 10ms/step - loss: 0.5883 - accuracy: 0.7019 - val_loss: 0.5516 - val_accuracy: 0.7391\n",
      "Epoch 24/50\n",
      "508/508 [==============================] - 5s 10ms/step - loss: 0.5792 - accuracy: 0.7046 - val_loss: 0.5252 - val_accuracy: 0.7509\n",
      "Epoch 25/50\n",
      "508/508 [==============================] - 5s 9ms/step - loss: 0.5737 - accuracy: 0.7063 - val_loss: 0.5367 - val_accuracy: 0.7237\n",
      "Epoch 26/50\n",
      "508/508 [==============================] - 5s 10ms/step - loss: 0.5696 - accuracy: 0.7105 - val_loss: 0.4932 - val_accuracy: 0.7752\n",
      "Epoch 27/50\n",
      "508/508 [==============================] - 5s 10ms/step - loss: 0.5632 - accuracy: 0.7117 - val_loss: 0.5097 - val_accuracy: 0.7531\n",
      "Epoch 28/50\n",
      "508/508 [==============================] - 5s 10ms/step - loss: 0.5550 - accuracy: 0.7164 - val_loss: 0.4902 - val_accuracy: 0.7848\n",
      "Epoch 29/50\n",
      "508/508 [==============================] - 5s 10ms/step - loss: 0.5472 - accuracy: 0.7230 - val_loss: 0.5081 - val_accuracy: 0.7458\n",
      "Epoch 30/50\n",
      "508/508 [==============================] - 5s 10ms/step - loss: 0.5714 - accuracy: 0.7073 - val_loss: 0.5075 - val_accuracy: 0.7620\n",
      "Epoch 31/50\n",
      "508/508 [==============================] - 6s 11ms/step - loss: 0.5563 - accuracy: 0.7208 - val_loss: 0.5203 - val_accuracy: 0.7458\n",
      "Epoch 32/50\n",
      "508/508 [==============================] - 5s 9ms/step - loss: 0.5419 - accuracy: 0.7319 - val_loss: 0.4772 - val_accuracy: 0.7811\n",
      "Epoch 33/50\n",
      "508/508 [==============================] - 5s 11ms/step - loss: 0.5464 - accuracy: 0.7277 - val_loss: 0.5213 - val_accuracy: 0.7693\n",
      "Epoch 34/50\n",
      "508/508 [==============================] - 5s 10ms/step - loss: 0.5499 - accuracy: 0.7218 - val_loss: 0.5017 - val_accuracy: 0.7738\n",
      "Epoch 35/50\n",
      "508/508 [==============================] - 5s 10ms/step - loss: 0.5477 - accuracy: 0.7275 - val_loss: 0.5810 - val_accuracy: 0.6979\n",
      "Epoch 36/50\n",
      "508/508 [==============================] - 5s 9ms/step - loss: 0.5451 - accuracy: 0.7290 - val_loss: 0.4789 - val_accuracy: 0.7826\n",
      "Epoch 37/50\n",
      "508/508 [==============================] - 5s 9ms/step - loss: 0.5363 - accuracy: 0.7339 - val_loss: 0.4695 - val_accuracy: 0.7922\n",
      "Epoch 38/50\n",
      "508/508 [==============================] - 5s 9ms/step - loss: 0.5314 - accuracy: 0.7388 - val_loss: 0.4834 - val_accuracy: 0.7848\n",
      "Epoch 39/50\n",
      "508/508 [==============================] - 5s 9ms/step - loss: 0.5290 - accuracy: 0.7403 - val_loss: 0.5010 - val_accuracy: 0.7686\n",
      "Epoch 40/50\n",
      "508/508 [==============================] - 5s 9ms/step - loss: 0.5304 - accuracy: 0.7361 - val_loss: 0.5571 - val_accuracy: 0.7229\n",
      "Epoch 41/50\n",
      "508/508 [==============================] - 5s 9ms/step - loss: 0.5300 - accuracy: 0.7368 - val_loss: 0.5479 - val_accuracy: 0.7340\n",
      "Epoch 42/50\n",
      "508/508 [==============================] - 5s 9ms/step - loss: 0.5204 - accuracy: 0.7454 - val_loss: 0.5522 - val_accuracy: 0.7281\n",
      "Epoch 43/50\n",
      "508/508 [==============================] - 5s 9ms/step - loss: 0.5211 - accuracy: 0.7489 - val_loss: 0.5569 - val_accuracy: 0.7229\n",
      "Epoch 44/50\n",
      "508/508 [==============================] - 5s 9ms/step - loss: 0.5285 - accuracy: 0.7331 - val_loss: 0.5309 - val_accuracy: 0.7399\n",
      "Epoch 45/50\n",
      "508/508 [==============================] - 5s 10ms/step - loss: 0.5318 - accuracy: 0.7388 - val_loss: 0.4927 - val_accuracy: 0.7789\n",
      "Epoch 46/50\n",
      "508/508 [==============================] - 5s 10ms/step - loss: 0.5202 - accuracy: 0.7422 - val_loss: 0.5659 - val_accuracy: 0.7104\n",
      "Epoch 47/50\n",
      "508/508 [==============================] - 5s 10ms/step - loss: 0.5102 - accuracy: 0.7560 - val_loss: 0.4513 - val_accuracy: 0.8040\n",
      "Epoch 48/50\n",
      "508/508 [==============================] - 5s 10ms/step - loss: 0.5079 - accuracy: 0.7536 - val_loss: 0.4703 - val_accuracy: 0.7981\n",
      "Epoch 49/50\n",
      "508/508 [==============================] - 5s 10ms/step - loss: 0.5146 - accuracy: 0.7541 - val_loss: 0.4691 - val_accuracy: 0.7988\n",
      "Epoch 50/50\n",
      "508/508 [==============================] - 5s 10ms/step - loss: 0.5129 - accuracy: 0.7477 - val_loss: 0.4448 - val_accuracy: 0.8106\n",
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.84      0.74      0.79       643\n",
      "        real       0.79      0.87      0.83       714\n",
      "\n",
      "    accuracy                           0.81      1357\n",
      "   macro avg       0.81      0.81      0.81      1357\n",
      "weighted avg       0.81      0.81      0.81      1357\n",
      "\n",
      "[INFO] serializing network to 'liveness.model'...\n",
      "INFO:tensorflow:Assets written to: liveness.model\\assets\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# construct the argument parser and parse the arguments\n",
    "# ap = argparse.ArgumentParser()\n",
    "# ap.add_argument(\"-d\", \"--dataset\", required=True,\n",
    "# \thelp=\"path to input dataset\")\n",
    "# ap.add_argument(\"-m\", \"--model\", type=str, required=True,\n",
    "# \thelp=\"path to trained model\")\n",
    "# ap.add_argument(\"-l\", \"--le\", type=str, required=True,\n",
    "# \thelp=\"path to label encoder\")\n",
    "# ap.add_argument(\"-p\", \"--plot\", type=str, default=\"plot.png\",\n",
    "# \thelp=\"path to output loss/accuracy plot\")\n",
    "# args = vars(ap.parse_args())\n",
    "\n",
    "# initialize the initial learning rate, batch size, and number of\n",
    "# epochs to train for\n",
    "INIT_LR = 1e-4\n",
    "BS = 8\n",
    "EPOCHS = 50\n",
    "\n",
    "# grab the list of images in our dataset directory, then initialize\n",
    "# the list of data (i.e., images) and class images\n",
    "# print(\"[INFO] loading images...\")\n",
    "# imagePaths = list(paths.list_images(args[\"dataset\"]))\n",
    "# data = []\n",
    "# labels = []\n",
    "\n",
    "# for imagePath in imagePaths:\n",
    "# \t# extract the class label from the filename, load the image and\n",
    "# \t# resize it to be a fixed 32x32 pixels, ignoring aspect ratio\n",
    "# \tlabel = imagePath.split(os.path.sep)[-2]\n",
    "# \timage = cv2.imread(imagePath)\n",
    "# \timage = cv2.resize(image, (32, 32))\n",
    "\n",
    "# \t# update the data and labels lists, respectively\n",
    "# \tdata.append(image)\n",
    "# \tlabels.append(label)\n",
    "\n",
    "# convert the data into a NumPy array, then preprocess it by scaling\n",
    "# all pixel intensities to the range [0, 1]\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "\n",
    "# encode the labels (which are currently strings) as integers and then\n",
    "# one-hot encode them\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "labels = np_utils.to_categorical(labels, 2)\n",
    "\n",
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
    "\ttest_size=0.25, random_state=42)\n",
    "\n",
    "# construct the training image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=20, zoom_range=0.15,\n",
    "\twidth_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,\n",
    "\thorizontal_flip=True, fill_mode=\"nearest\")\n",
    "\n",
    "# initialize the optimizer and model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model = LivenessNet.build(width=32, height=32, depth=3,\n",
    "\tclasses=len(le.classes_))\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "\n",
    "# train the network\n",
    "print(\"[INFO] training network for {} epochs...\".format(EPOCHS))\n",
    "H = model.fit_generator(aug.flow(trainX, trainY, batch_size=BS),\n",
    "\tvalidation_data=(testX, testY), steps_per_epoch=len(trainX) // BS,\n",
    "\tepochs=EPOCHS)\n",
    "\n",
    "# evaluate the network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(testX, batch_size=BS)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "\tpredictions.argmax(axis=1), target_names=le.classes_))\n",
    "\n",
    "# save the network to disk\n",
    "model_path = \"liveness.model\"\n",
    "print(\"[INFO] serializing network to '{}'...\".format(model_path))\n",
    "model.save(model_path)\n",
    "\n",
    "# save the label encoder to disk\n",
    "le_path = \"le.pickle\"\n",
    "f = open(le_path, \"wb\")\n",
    "f.write(pickle.dumps(le))\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "plot_path = \"plot.png\"\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, EPOCHS), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, EPOCHS), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, EPOCHS), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, EPOCHS), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(plot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.921705424785614, 0.826959490776062, 0.8148155808448792, 0.7609246969223022, 0.7262651920318604, 0.7257144451141357, 0.6929773688316345, 0.6642053127288818, 0.6601290106773376, 0.6517049670219421, 0.6397360563278198, 0.6391095519065857, 0.6222884058952332, 0.6199017763137817, 0.6010035872459412, 0.5980288982391357, 0.5832599997520447, 0.5869350433349609, 0.5858795642852783, 0.5698794722557068, 0.561039388179779, 0.5669911503791809, 0.5632133483886719, 0.5600284337997437, 0.5557820796966553, 0.5446659326553345, 0.5476539731025696, 0.5314794778823853, 0.5394994616508484, 0.5442585945129395, 0.5313345193862915, 0.5268172025680542, 0.5231662392616272, 0.5131305456161499, 0.517967164516449, 0.5100886821746826, 0.5207077264785767, 0.519129753112793, 0.5101861357688904, 0.5068457722663879, 0.5088955163955688, 0.5117530822753906, 0.5130264163017273, 0.49954378604888916, 0.5118096470832825, 0.4990816116333008, 0.5091240406036377, 0.5056278705596924, 0.5073855519294739, 0.49755439162254333], 'accuracy': [0.5544067025184631, 0.5896110534667969, 0.582225501537323, 0.6208764314651489, 0.6189069151878357, 0.6253077387809753, 0.6400787830352783, 0.658788800239563, 0.6501723527908325, 0.6701132655143738, 0.6681437492370605, 0.6674052476882935, 0.6777449250221252, 0.6797144412994385, 0.6932545304298401, 0.698178231716156, 0.6999015212059021, 0.7070408463478088, 0.706302285194397, 0.710487425327301, 0.7122107148170471, 0.7166420221328735, 0.7176268100738525, 0.7215657234191895, 0.7186115384101868, 0.7269817590713501, 0.7368291616439819, 0.7405219078063965, 0.7311668992042542, 0.7264894247055054, 0.7380600571632385, 0.7321516275405884, 0.7434760928153992, 0.7525849342346191, 0.7471688985824585, 0.7523387670516968, 0.7407680749893188, 0.7479074597358704, 0.7538158297538757, 0.7496307492256165, 0.7543082237243652, 0.755785346031189, 0.7459379434585571, 0.7604628205299377, 0.750861644744873, 0.7597242593765259, 0.7594780921936035, 0.755785346031189, 0.7602166533470154, 0.7612013816833496], 'val_loss': [0.771698534488678, 0.7191084623336792, 0.6648391485214233, 0.6506179571151733, 0.6961497068405151, 0.6536659002304077, 0.6661354303359985, 0.6140349507331848, 0.629485547542572, 0.5814857482910156, 0.6104689836502075, 0.5992090106010437, 0.6002313494682312, 0.635022759437561, 0.6781623363494873, 0.6433865427970886, 0.637515664100647, 0.5321492552757263, 0.7384757995605469, 0.5863982439041138, 0.6491419076919556, 0.6469854116439819, 0.7085796594619751, 0.5367519855499268, 0.6448264122009277, 0.8470036387443542, 0.6450396180152893, 0.6939987540245056, 0.5742152333259583, 0.5953661203384399, 0.650903046131134, 0.4919283390045166, 0.6628097891807556, 0.6287264227867126, 0.5552253723144531, 0.5781886577606201, 0.5643660426139832, 0.4891006052494049, 0.4891873300075531, 0.49864885210990906, 0.7100702524185181, 0.5402136445045471, 0.7121601104736328, 0.5692901611328125, 0.6567702293395996, 0.6282208561897278, 0.5883661508560181, 0.6310537457466125, 0.571614682674408, 0.6606770753860474], 'val_accuracy': [0.5549005270004272, 0.6116433143615723, 0.6374354958534241, 0.6484892964363098, 0.6123802661895752, 0.6389093399047852, 0.6285924911499023, 0.6595430970191956, 0.6580692529678345, 0.6882829666137695, 0.6772291660308838, 0.664701521396637, 0.6809138059616089, 0.6470154523849487, 0.638172447681427, 0.6993367671966553, 0.666912317276001, 0.7413411736488342, 0.6109064221382141, 0.6853352785110474, 0.666912317276001, 0.666175365447998, 0.6750184297561646, 0.7302873730659485, 0.680176854133606, 0.6050110459327698, 0.6779661178588867, 0.653647780418396, 0.6978629231452942, 0.6897568106651306, 0.6779661178588867, 0.7479734420776367, 0.6853352785110474, 0.6868091225624084, 0.7118644118309021, 0.7118644118309021, 0.7155489921569824, 0.7649226188659668, 0.7531319260597229, 0.7612380385398865, 0.6698600053787231, 0.7406042814254761, 0.6580692529678345, 0.7243920564651489, 0.6853352785110474, 0.7059690356254578, 0.7266027927398682, 0.7000737190246582, 0.7192336320877075, 0.6875460743904114]}\n"
     ]
    }
   ],
   "source": [
    "print(H.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e009fd7a26827f4dfa9c6b7ca52e408c871ec95e1f37a45a7163d8a15e724551"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
